{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_snake(df):\n",
    "    colNames = []\n",
    "    for col in df.columns:\n",
    "        colNames.append(str.lower(col.replace(' ','_')))\n",
    "    df.columns = colNames\n",
    "\n",
    "def num_nulls(df, col):\n",
    "    a = []\n",
    "    for i in df[col]:\n",
    "        a.append(str(i))\n",
    "    return a\n",
    "\n",
    "def val_cou(df):\n",
    "    for col in df.columns:\n",
    "        if (df[col].value_counts().sum()) < 1460:\n",
    "            print((df[col].value_counts().sum()), col)\n",
    "        \n",
    "def response_feature_splitter(df, position: int):\n",
    "    col = df.columns[position]\n",
    "    features = df.copy().drop(columns=[col])\n",
    "    response = df.copy()[[col]]\n",
    "    return features, response   \n",
    "\n",
    "def neighborly_suggestions(features_all, y_train, y_test_loc, X_train, X_test, response_col):\n",
    "    lab_enc = LabelEncoder()\n",
    "    response_LE = lab_enc.fit_transform(y_train)\n",
    "    response_LE_df = pd.DataFrame(response_LE, columns = ['response'])\n",
    "\n",
    "    uno_caliente = OneHotEncoder(sparse=False)\n",
    "    uno_caliente.fit(features_all)\n",
    "    features_NoNAs_trans = uno_caliente.transform(X_train)\n",
    "    features_test_trans = uno_caliente.transform(X_test)\n",
    "    features_NoNAs_trans_df = pd.DataFrame(features_NoNAs_trans, columns=uno_caliente.get_feature_names())\n",
    "    features_test_trans_df = pd.DataFrame(features_test_trans, columns=uno_caliente.get_feature_names())\n",
    "\n",
    "    KNN_clf = KNeighborsClassifier()\n",
    "    KNN_clf.fit(features_NoNAs_trans_df, response_LE_df)\n",
    "\n",
    "    response_trans_pred = KNN_clf.predict(features_test_trans_df)\n",
    "    response_pred = lab_enc.inverse_transform(response_trans_pred)\n",
    "\n",
    "    missing_values = pd.DataFrame(response_pred, columns=[response_col])\n",
    "    missing_values.index = y_test_loc.index\n",
    "    missing_values.sort_index()\n",
    "    #print(f\"The missing value counts for columns with '?': \\n{missing_values.value_counts()}\")\n",
    "    return missing_values\n",
    "\n",
    "def NaN_fixer(main_df, y_train, missing_values, response_col):\n",
    "    response_new = pd.concat([y_train, missing_values], axis=0)\n",
    "    response_new.sort_index()\n",
    "    main_df[response_col] = response_new[response_col]\n",
    "    return main_df\n",
    "\n",
    "def null_breaker_1o2(df):   #this function finds columns with null values in them and sperates them as the response for predicting their values\n",
    "    resp_col = []                                                               #empty list to collect the response columns\n",
    "    feats_cols = []                                                             #empty list to collect the feature columns\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:                                            #ifelse loop grouping columns that have missing values and those that don't\n",
    "            resp_col.append(col)\n",
    "            #print(f\"columns with '?': {resp_col}\")                              #'?' is project specific\n",
    "        else:\n",
    "            feats_cols.append(col)\n",
    "\n",
    "    features_all = df.copy()[feats_cols]\n",
    "    response_all = df.copy()[resp_col]\n",
    "\n",
    "    return features_all, response_all  #outputs variables that are going to be needed throughout the machine\n",
    "\n",
    "def null_breaker_2o2(features_all, response_all, df):\n",
    "    for col in response_all.columns:\n",
    "        y_test_loc = response_all.loc[response_all[col].isna() == True, :]             #location of all the null responses\n",
    "        y_train = response_all[[col]].dropna()                                             #responses with nulls removed        \n",
    "        X_train = features_all.iloc[y_train.index, :]                               #features df with the rows matching null responses removed\n",
    "        X_test = features_all.iloc[y_test_loc.index, :]                           #df of feature rows with null responses\n",
    "        \n",
    "        missing_values = neighborly_suggestions(features_all, y_train, y_test_loc, X_train, X_test, col)\n",
    "        response_new = pd.concat([y_train, missing_values], axis=0)\n",
    "        response_new.sort_index()\n",
    "        df = pd.concat([df, response_new], axis=1)\n",
    "    return df\n",
    "\n",
    "def num_nulls(df, col):\n",
    "    a = []\n",
    "    for i in df[col]:\n",
    "        a.append(str(i))\n",
    "    return a\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
