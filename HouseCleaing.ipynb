{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_snake(df):\n",
    "    colNames = []\n",
    "    for col in df.columns:\n",
    "        colNames.append(str.lower(col.replace(' ','_')))\n",
    "    df.columns = colNames\n",
    "\n",
    "def num_nulls(df, col):\n",
    "    a = []\n",
    "    for i in df[col]:\n",
    "        a.append(str(i))\n",
    "    return a\n",
    "\n",
    "def val_cou(df):\n",
    "    for col in df.columns:\n",
    "        if (df[col].value_counts().sum()) < 1460:\n",
    "            print((df[col].value_counts().sum()), col)\n",
    "        \n",
    "def response_feature_splitter(df, position: int):\n",
    "    col = df.columns[position]\n",
    "    features = df.copy().drop(columns=[col])\n",
    "    response = df.copy()[[col]]\n",
    "    return features, response   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the data\n",
    "filename = 'train.csv'\n",
    "houses = pd.read_csv(filename)\n",
    "\n",
    "##convert columns to snake case\n",
    "ff = [houses]\n",
    "for df in ff:\n",
    "    lower_snake(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##inspect\n",
    "len(houses.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for duplicate values\n",
    "houses2 = houses.copy().drop(columns=['id'])\n",
    "houses2.duplicated().value_counts()\n",
    "#no complete duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain list of columns for easy use\n",
    "columns = []\n",
    "for col in houses.columns:\n",
    "    columns.append(col)\n",
    "print(columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin dealing with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for rows with too many null values\n",
    "houses2 = houses.copy()\n",
    "houses3 = houses2.dropna(thresh=70)\n",
    "nullFrame = houses2.loc[~houses2['id'].isin(houses3['id'])]  #looking for ids in houses2 are not in houses3 #these are the \"nullFrame\", the rows that have too many null values\n",
    "nullFrame['id']\n",
    "\n",
    "#not sure what this is for, but I feel like it might have taken me some work... so I am going to keep it\n",
    "#nullFrame.drop(columns=['mssubclass','mszoning','lotfrontage','lotarea','street','lotshape','landcontour','utilities','poolarea','miscval','mosold','yrsold','saletype','salecondition','saleprice','lotconfig','landslope','neighborhood','condition1','condition2','bldgtype','housestyle','overallqual','paveddrive','wooddecksf','openporchsf','enclosedporch','3ssnporch', 'screenporch','overallcond', 'yearbuilt', 'yearremodadd', 'roofstyle', 'roofmatl', 'exterior1st', 'exterior2nd', 'masvnrtype','garagecars', 'garagearea', 'fireplaces','masvnrarea', 'exterqual', 'extercond', 'foundation','functional','bsmtfinsf1','bsmtfinsf2','bsmtunfsf','totalbsmtsf', 'heating', 'heatingqc', 'centralair', 'electrical', '1stflrsf','2ndflrsf', 'lowqualfinsf', 'grlivarea','bsmtfullbath', 'bsmthalfbath', 'fullbath', 'halfbath', 'bedroomabvgr', 'kitchenabvgr'])\n",
    "\n",
    "## dropping rows with 70+ nulls\n",
    "temp = houses.copy()\n",
    "houses4 = temp.loc[~temp['id'].isin(nullFrame['id'])]\n",
    "houses4 = houses4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset into numerical and categorical data\n",
    "house_cats = houses4.select_dtypes(include=['object'])\n",
    "house_nums = houses4.select_dtypes(include=np.number)\n",
    "\n",
    "## columns next to their total non-null values\n",
    "print(val_cou(house_cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_cou(house_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborly_suggestions(features_all, y_train, y_test_loc, X_train, X_test, response_col):\n",
    "    lab_enc = LabelEncoder()\n",
    "    response_LE = lab_enc.fit_transform(y_train)\n",
    "    response_LE_df = pd.DataFrame(response_LE, columns = ['response'])\n",
    "\n",
    "    uno_caliente = OneHotEncoder(sparse=False)\n",
    "    uno_caliente.fit(features_all)\n",
    "    features_NoNAs_trans = uno_caliente.transform(X_train)\n",
    "    features_test_trans = uno_caliente.transform(X_test)\n",
    "    features_NoNAs_trans_df = pd.DataFrame(features_NoNAs_trans, columns=uno_caliente.get_feature_names())\n",
    "    features_test_trans_df = pd.DataFrame(features_test_trans, columns=uno_caliente.get_feature_names())\n",
    "\n",
    "    KNN_clf = KNeighborsClassifier()\n",
    "    KNN_clf.fit(features_NoNAs_trans_df, response_LE_df)\n",
    "\n",
    "    response_trans_pred = KNN_clf.predict(features_test_trans_df)\n",
    "    response_pred = lab_enc.inverse_transform(response_trans_pred)\n",
    "\n",
    "    missing_values = pd.DataFrame(response_pred, columns=[response_col])\n",
    "    missing_values.index = y_test_loc.index\n",
    "    missing_values.sort_index()\n",
    "    #print(f\"The missing value counts for columns with '?': \\n{missing_values.value_counts()}\")\n",
    "    return missing_values\n",
    "\n",
    "def NaN_fixer(main_df, y_train, missing_values, response_col):\n",
    "    response_new = pd.concat([y_train, missing_values], axis=0)\n",
    "    response_new.sort_index()\n",
    "    main_df[response_col] = response_new[response_col]\n",
    "    return main_df\n",
    "\n",
    "def null_breaker_1o2(df):   #this function finds columns with null values in them and sperates them as the response for predicting their values\n",
    "    resp_col = []                                                               #empty list to collect the response columns\n",
    "    feats_cols = []                                                             #empty list to collect the feature columns\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:                                            #ifelse loop grouping columns that have missing values and those that don't\n",
    "            resp_col.append(col)\n",
    "            #print(f\"columns with '?': {resp_col}\")                              #'?' is project specific\n",
    "        else:\n",
    "            feats_cols.append(col)\n",
    "\n",
    "    features_all = df.copy()[feats_cols]\n",
    "    response_all = df.copy()[resp_col]\n",
    "\n",
    "    return features_all, response_all  #outputs variables that are going to be needed throughout the machine\n",
    "\n",
    "def null_breaker_2o2(features_all, response_all, df):\n",
    "    for col in response_all.columns:\n",
    "        y_test_loc = response_all.loc[response_all[col].isna() == True, :]             #location of all the null responses\n",
    "        y_train = response_all[[col]].dropna()                                             #responses with nulls removed        \n",
    "        X_train = features_all.iloc[y_train.index, :]                               #features df with the rows matching null responses removed\n",
    "        X_test = features_all.iloc[y_test_loc.index, :]                           #df of feature rows with null responses\n",
    "        \n",
    "        missing_values = neighborly_suggestions(features_all, y_train, y_test_loc, X_train, X_test, col)\n",
    "        response_new = pd.concat([y_train, missing_values], axis=0)\n",
    "        response_new.sort_index()\n",
    "        df = pd.concat([df, response_new], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Category Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all, response_all = null_breaker_1o2(house_cats)\n",
    "responses_full = null_breaker_2o2(features_all, response_all, houses4[['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_cats_noNaN = pd.concat([responses_full, features_all], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_cats_noNaN.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_nulls(df, col):\n",
    "    a = []\n",
    "    for i in df[col]:\n",
    "        a.append(str(i))\n",
    "    return a\n",
    "num_nulls(house_nums, 'lotfrontage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_feature_splitter(house_nums)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
